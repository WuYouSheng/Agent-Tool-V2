#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import base64
import hashlib
from scapy.all import *

class EmbeddingDiagnostic:
    """è¨ºæ–·Embeddingå’Œé‚„åŸéç¨‹çš„å•é¡Œ"""
    
    def __init__(self):
        self.issues_found = []
    
    def diagnose_pcap_files(self, incoming_pcap, embedded_pcap, restored_pcap):
        """è¨ºæ–·ä¸‰å€‹PCAPæª”æ¡ˆçš„å•é¡Œ"""
        print("ğŸ” é–‹å§‹è¨ºæ–·Embeddingé‚„åŸå•é¡Œ...")
        print("=" * 60)
        
        # 1. è®€å–ä¸¦åˆ†æPCAPæª”æ¡ˆ
        incoming_packets = rdpcap(incoming_pcap)
        embedded_packets = rdpcap(embedded_pcap)
        restored_packets = rdpcap(restored_pcap)
        
        print(f"ğŸ“‚ æª”æ¡ˆè¼‰å…¥:")
        print(f"   ä¾†æºå°åŒ…: {len(incoming_packets)} å€‹")
        print(f"   åµŒå…¥å°åŒ…: {len(embedded_packets)} å€‹")  
        print(f"   é‚„åŸå°åŒ…: {len(restored_packets)} å€‹")
        
        # 2. åˆ†æåµŒå…¥å°åŒ…æ ¼å¼
        self._analyze_embedded_packets(embedded_packets[:5])  # åªåˆ†æå‰5å€‹
        
        # 3. åˆ†æé‚„åŸå°åŒ…
        self._analyze_restored_packets(restored_packets[:5])
        
        # 4. æ¯”è¼ƒåŸå§‹å’Œé‚„åŸå°åŒ…çš„é›œæ¹Šå€¼
        self._compare_packet_hashes(incoming_packets[:10], restored_packets[:10])
        
        # 5. æ¸¬è©¦embeddingå’Œé‚„åŸæµç¨‹
        self._test_embedding_restoration_flow(incoming_packets[0] if incoming_packets else None)
        
        # 6. ç¸½çµå•é¡Œ
        self._summarize_issues()
    
    def _analyze_embedded_packets(self, packets):
        """åˆ†æåµŒå…¥å°åŒ…çš„æ ¼å¼å’Œå…§å®¹"""
        print("\nğŸ” åˆ†æåµŒå…¥å°åŒ…æ ¼å¼:")
        
        for i, packet in enumerate(packets):
            print(f"\nå°åŒ… {i+1}:")
            
            if Raw not in packet:
                print("   âŒ æ²’æœ‰Raw payload")
                self.issues_found.append("åµŒå…¥å°åŒ…ç¼ºå°‘Raw payload")
                continue
            
            try:
                payload = packet[Raw].load.decode('utf-8')
                print(f"   Payloadå¤§å°: {len(payload)} bytes")
                
                # å˜—è©¦è§£æJSON
                try:
                    data = json.loads(payload)
                    print("   âœ… JSONæ ¼å¼æ­£ç¢º")
                    
                    # æª¢æŸ¥å¿…è¦æ¬„ä½
                    if "fragment_info" in data:
                        print("   ğŸ“¦ é€™æ˜¯åˆ†ç‰‡å°åŒ…")
                        fragment_info = data["fragment_info"]
                        print(f"      UUID: {fragment_info.get('fragment_uuid', 'missing')[:16]}...")
                        print(f"      åˆ†ç‰‡: {fragment_info.get('fragment_index', 'missing')}/{fragment_info.get('total_fragments', 'missing')}")
                    elif "metadata" in data and "original_packet" in data:
                        print("   ğŸ“‹ é€™æ˜¯å®Œæ•´å°åŒ…")
                        metadata = data["metadata"]
                        original = data["original_packet"]
                        print(f"      UUID: {metadata.get('embed_uuid', 'missing')[:16]}...")
                        print(f"      åŸå§‹å¤§å°: {original.get('length', 'missing')} bytes")
                        print(f"      åŸå§‹ä¾†æº: {original.get('original_src', 'missing')}")
                        print(f"      åŸå§‹ç›®æ¨™: {original.get('original_dst', 'missing')}")
                    else:
                        print("   âŒ ç¼ºå°‘å¿…è¦æ¬„ä½")
                        self.issues_found.append("åµŒå…¥å°åŒ…ç¼ºå°‘å¿…è¦æ¬„ä½")
                        
                except json.JSONDecodeError as e:
                    print(f"   âŒ JSONè§£æå¤±æ•—: {e}")
                    self.issues_found.append("åµŒå…¥å°åŒ…JSONæ ¼å¼éŒ¯èª¤")
                    print(f"   å‰100å­—å…ƒ: {payload[:100]}")
                    
            except UnicodeDecodeError:
                print("   âŒ UTF-8è§£ç¢¼å¤±æ•—")
                self.issues_found.append("åµŒå…¥å°åŒ…ç·¨ç¢¼å•é¡Œ")
    
    def _analyze_restored_packets(self, packets):
        """åˆ†æé‚„åŸå°åŒ…"""
        print("\nğŸ” åˆ†æé‚„åŸå°åŒ…:")
        
        for i, packet in enumerate(packets):
            print(f"\né‚„åŸå°åŒ… {i+1}:")
            print(f"   å¤§å°: {len(bytes(packet))} bytes")
            print(f"   é›œæ¹Š: {hashlib.sha256(bytes(packet)).hexdigest()[:16]}...")
            
            if IP in packet:
                print(f"   IP: {packet[IP].src} -> {packet[IP].dst}")
                
            if TCP in packet:
                print(f"   TCP: {packet[TCP].sport} -> {packet[TCP].dport}")
                
            if Raw in packet:
                print(f"   Payload: {len(packet[Raw].load)} bytes")
    
    def _compare_packet_hashes(self, incoming_packets, restored_packets):
        """æ¯”è¼ƒåŸå§‹å’Œé‚„åŸå°åŒ…çš„é›œæ¹Šå€¼"""
        print("\nğŸ” é›œæ¹Šå€¼æ¯”è¼ƒåˆ†æ:")
        
        incoming_hashes = []
        for packet in incoming_packets:
            hash_val = hashlib.sha256(bytes(packet)).hexdigest()
            incoming_hashes.append({
                'hash': hash_val,
                'size': len(bytes(packet)),
                'summary': packet.summary()
            })
        
        restored_hashes = []
        for packet in restored_packets:
            hash_val = hashlib.sha256(bytes(packet)).hexdigest()
            restored_hashes.append({
                'hash': hash_val,
                'size': len(bytes(packet)),
                'summary': packet.summary()
            })
        
        print(f"\nåŸå§‹å°åŒ…é›œæ¹Š (å‰5å€‹):")
        for i, info in enumerate(incoming_hashes[:5]):
            print(f"   {i+1}. {info['hash'][:16]}... ({info['size']} bytes)")
        
        print(f"\né‚„åŸå°åŒ…é›œæ¹Š (å‰5å€‹):")
        for i, info in enumerate(restored_hashes[:5]):
            print(f"   {i+1}. {info['hash'][:16]}... ({info['size']} bytes)")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ä»»ä½•åŒ¹é…
        incoming_hash_set = {info['hash'] for info in incoming_hashes}
        restored_hash_set = {info['hash'] for info in restored_hashes}
        
        matches = incoming_hash_set.intersection(restored_hash_set)
        print(f"\nåŒ¹é…çš„é›œæ¹Šå€¼: {len(matches)} å€‹")
        
        if len(matches) == 0:
            self.issues_found.append("æ²’æœ‰ä»»ä½•é›œæ¹Šå€¼åŒ¹é… - å°åŒ…é‚„åŸå¯èƒ½æœ‰å•é¡Œ")
    
    def _test_embedding_restoration_flow(self, sample_packet):
        """æ¸¬è©¦å®Œæ•´çš„embeddingå’Œé‚„åŸæµç¨‹"""
        if not sample_packet:
            return
            
        print("\nğŸ§ª æ¸¬è©¦embeddingå’Œé‚„åŸæµç¨‹:")
        
        try:
            # æ¨¡æ“¬Embeddingéç¨‹
            from Embedding import PacketEmbedder
            embedder = PacketEmbedder()
            
            print("   1. æ¸¬è©¦å°åŒ…åºåˆ—åŒ–...")
            serialized = embedder.serialize_packet(sample_packet)
            if serialized:
                print("   âœ… åºåˆ—åŒ–æˆåŠŸ")
            else:
                print("   âŒ åºåˆ—åŒ–å¤±æ•—")
                self.issues_found.append("å°åŒ…åºåˆ—åŒ–å¤±æ•—")
                return
            
            print("   2. æ¸¬è©¦å°åŒ…åµŒå…¥...")
            embedded_packets = embedder.embed_packet(sample_packet, "127.0.0.1", 9999)
            if embedded_packets:
                print(f"   âœ… åµŒå…¥æˆåŠŸï¼Œç”¢ç”Ÿ {len(embedded_packets)} å€‹å°åŒ…")
            else:
                print("   âŒ åµŒå…¥å¤±æ•—")
                self.issues_found.append("å°åŒ…åµŒå…¥å¤±æ•—")
                return
            
            print("   3. æ¸¬è©¦å°åŒ…é‚„åŸ...")
            
            # æ¨¡æ“¬é‚„åŸéç¨‹
            for embedded_packet in embedded_packets:
                if Raw in embedded_packet:
                    try:
                        payload = embedded_packet[Raw].load.decode('utf-8')
                        embedded_data = json.loads(payload)
                        
                        if "fragment_info" not in embedded_data:
                            # å®Œæ•´å°åŒ…
                            original_data_b64 = embedded_data['original_packet']['data']
                            original_bytes = base64.b64decode(original_data_b64)
                            restored_packet = Ether(original_bytes)
                            
                            # æ¯”è¼ƒé›œæ¹Šå€¼
                            original_hash = hashlib.sha256(bytes(sample_packet)).hexdigest()
                            restored_hash = hashlib.sha256(bytes(restored_packet)).hexdigest()
                            
                            print(f"   åŸå§‹é›œæ¹Š: {original_hash[:16]}...")
                            print(f"   é‚„åŸé›œæ¹Š: {restored_hash[:16]}...")
                            
                            if original_hash == restored_hash:
                                print("   âœ… é‚„åŸæˆåŠŸï¼Œé›œæ¹Šå€¼åŒ¹é…")
                            else:
                                print("   âŒ é‚„åŸå¤±æ•—ï¼Œé›œæ¹Šå€¼ä¸åŒ¹é…")
                                self.issues_found.append("æ¸¬è©¦é‚„åŸæ™‚é›œæ¹Šå€¼ä¸åŒ¹é…")
                                
                                # è©³ç´°åˆ†æå·®ç•°
                                self._analyze_packet_differences(sample_packet, restored_packet)
                            
                            break
                            
                    except Exception as e:
                        print(f"   âŒ é‚„åŸéç¨‹éŒ¯èª¤: {e}")
                        self.issues_found.append(f"é‚„åŸéç¨‹éŒ¯èª¤: {e}")
        
        except Exception as e:
            print(f"   âŒ æ¸¬è©¦æµç¨‹éŒ¯èª¤: {e}")
            self.issues_found.append(f"æ¸¬è©¦æµç¨‹éŒ¯èª¤: {e}")
    
    def _analyze_packet_differences(self, original, restored):
        """åˆ†æåŸå§‹å’Œé‚„åŸå°åŒ…çš„å·®ç•°"""
        print("\nğŸ” å°åŒ…å·®ç•°åˆ†æ:")
        
        original_bytes = bytes(original)
        restored_bytes = bytes(restored)
        
        print(f"   åŸå§‹å°åŒ…å¤§å°: {len(original_bytes)} bytes")
        print(f"   é‚„åŸå°åŒ…å¤§å°: {len(restored_bytes)} bytes")
        
        if len(original_bytes) != len(restored_bytes):
            print("   âŒ å°åŒ…å¤§å°ä¸åŒ")
            self.issues_found.append("é‚„åŸå°åŒ…å¤§å°èˆ‡åŸå§‹å°åŒ…ä¸åŒ")
        
        # æ¯”è¼ƒå‰50å€‹ä½å…ƒçµ„
        min_len = min(len(original_bytes), len(restored_bytes))
        for i in range(min(50, min_len)):
            if original_bytes[i] != restored_bytes[i]:
                print(f"   âŒ ä½å…ƒçµ„ {i}: åŸå§‹={original_bytes[i]:02x}, é‚„åŸ={restored_bytes[i]:02x}")
                break
        
        # åˆ†æå°åŒ…å±¤ç´š
        print("\n   å±¤ç´šæ¯”è¼ƒ:")
        print(f"   åŸå§‹: {original.summary()}")
        print(f"   é‚„åŸ: {restored.summary()}")
    
    def _summarize_issues(self):
        """ç¸½çµç™¼ç¾çš„å•é¡Œ"""
        print("\n" + "=" * 60)
        print("ğŸ¯ è¨ºæ–·çµæœç¸½çµ")
        print("=" * 60)
        
        if not self.issues_found:
            print("âœ… æ²’æœ‰ç™¼ç¾æ˜é¡¯å•é¡Œ")
        else:
            print(f"âŒ ç™¼ç¾ {len(self.issues_found)} å€‹å•é¡Œ:")
            for i, issue in enumerate(self.issues_found, 1):
                print(f"   {i}. {issue}")
        
        print("\nğŸ”§ å»ºè­°ä¿®å¾©æªæ–½:")
        
        if any("é›œæ¹Šå€¼ä¸åŒ¹é…" in issue for issue in self.issues_found):
            print("   1. æª¢æŸ¥å°åŒ…é‡å»ºéç¨‹æ˜¯å¦å®Œæ•´ä¿ç•™æ‰€æœ‰æ¬„ä½")
            print("   2. ç¢ºèªEtherå±¤çš„é‡å»ºæ˜¯å¦æ­£ç¢º")
            print("   3. æª¢æŸ¥æ˜¯å¦æœ‰é¡å¤–çš„headerè¢«æ·»åŠ æˆ–ç§»é™¤")
        
        if any("JSON" in issue for issue in self.issues_found):
            print("   4. æª¢æŸ¥åµŒå…¥å°åŒ…çš„JSONæ ¼å¼å’Œç·¨ç¢¼")
        
        if any("åˆ†ç‰‡" in issue for issue in self.issues_found):
            print("   5. æª¢æŸ¥åˆ†ç‰‡é‡çµ„é‚è¼¯")
        
        print("   6. å»ºè­°åœ¨Embedding.pyå’ŒAnalyst.pyä¸­å¢åŠ æ›´å¤šé™¤éŒ¯è¼¸å‡º")
        print("   7. è€ƒæ…®ä½¿ç”¨ç›¸åŒçš„å°åŒ…é‡å»ºæ–¹æ³•")

# ä½¿ç”¨æ–¹æ³•
def main():
    print("ğŸ” Embeddingè¨ºæ–·å·¥å…·")
    print("=" * 60)
    
    # è«‹ä¿®æ”¹ç‚ºä½ çš„å¯¦éš›æª”æ¡ˆè·¯å¾‘
    incoming_pcap = "incoming_packets_5006_20250526_212452.pcap"
    embedded_pcap = "embedded_packets_20_20250526_212452.pcap"
    restored_pcap = "restored_packets_20250526_212452.pcap"
    
    diagnostic = EmbeddingDiagnostic()
    
    try:
        diagnostic.diagnose_pcap_files(incoming_pcap, embedded_pcap, restored_pcap)
    except FileNotFoundError as e:
        print(f"âŒ æª”æ¡ˆæœªæ‰¾åˆ°: {e}")
        print("è«‹ç¢ºèªPCAPæª”æ¡ˆè·¯å¾‘æ­£ç¢º")
    except Exception as e:
        print(f"âŒ è¨ºæ–·éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    main()