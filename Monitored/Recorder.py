#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import json
import uuid
import os
import time
from datetime import datetime
from pathlib import Path
import threading


class Recorder:
    def __init__(self, save_path="./", current_uuid=None):
        """
        åˆå§‹åŒ–è¨˜éŒ„å™¨

        Args:
            save_path (str): å„²å­˜è·¯å¾‘ï¼Œé è¨­ç‚ºç•¶å‰ç›®éŒ„
            current_uuid (uuid): æœå‹™çš„UUIDï¼Œå¦‚æœæœªæä¾›æœƒè‡ªå‹•ç”Ÿæˆ
        """
        self.save_path = Path(save_path)
        self.record_uuid = current_uuid if current_uuid else uuid.uuid4()
        self.serial_counter = 0  # å°åŒ…åºåˆ—è™Ÿè¨ˆæ•¸å™¨
        self.records = []  # è¨˜éŒ„åˆ—è¡¨
        self.lock = threading.Lock()  # åŸ·è¡Œç·’é–ï¼Œç¢ºä¿å¤šåŸ·è¡Œç·’å®‰å…¨

        # ç¢ºä¿å„²å­˜ç›®éŒ„å­˜åœ¨
        self.save_path.mkdir(parents=True, exist_ok=True)

        # å»ºç«‹è¨˜éŒ„æª”æ¡ˆè·¯å¾‘
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.json_filename = f"embedded_packets_record_{timestamp}.json"
        self.json_filepath = self.save_path / self.json_filename

        print(f"è¨˜éŒ„å™¨åˆå§‹åŒ–å®Œæˆ:")
        print(f"  æœå‹™UUID: {self.record_uuid}")
        print(f"  å„²å­˜è·¯å¾‘: {self.json_filepath}")

    def record_embedded_packet(self, embedded_packet, original_packet_info=None, metadata=None, fragment_info=None):
        """
        è¨˜éŒ„åµŒå…¥å¼å°åŒ…è³‡è¨Š

        Args:
            embedded_packet: åµŒå…¥å¼å°åŒ…ï¼ˆScapyå°åŒ…æ ¼å¼ï¼‰
            original_packet_info (dict): åŸå§‹å°åŒ…è³‡è¨Š
            metadata (dict): å°åŒ…çš„metadataè³‡è¨Š
            fragment_info (dict): åˆ†ç‰‡è³‡è¨Šï¼ˆå¦‚æœæ˜¯åˆ†ç‰‡å°åŒ…ï¼‰
        """
        try:
            with self.lock:
                self.serial_counter += 1

                # å»ºç«‹è¨˜éŒ„é …ç›®
                record_entry = self._create_record_entry(
                    embedded_packet,
                    original_packet_info,
                    metadata,
                    fragment_info
                )

                # åŠ å…¥è¨˜éŒ„åˆ—è¡¨
                self.records.append(record_entry)

                # å³æ™‚å„²å­˜åˆ°JSONæª”æ¡ˆ
                self._save_to_json()

                print(f"ğŸ“ å°åŒ…è¨˜éŒ„å®Œæˆ (åºè™Ÿ: {self.serial_counter})")
                print(f"   ServiceID: {record_entry['ServiceID']}")
                print(f"   ç›®æ¨™: {record_entry['DestinationIP']}:{record_entry['DestinationPort']}")

                return True

        except Exception as e:
            print(f"âŒ è¨˜éŒ„å°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

    def _create_record_entry(self, embedded_packet, original_packet_info, metadata, fragment_info):
        """
        å»ºç«‹è¨˜éŒ„é …ç›®

        Returns:
            dict: åŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½çš„è¨˜éŒ„é …ç›®
        """
        # å¾embedded_packetæå–åŸºæœ¬è³‡è¨Š
        source_ip = "unknown"
        source_port = "unknown"
        destination_ip = "unknown"
        destination_port = "unknown"

        try:
            if hasattr(embedded_packet, 'src'):
                source_ip = str(embedded_packet.src)
            elif hasattr(embedded_packet, '__getitem__') and 'IP' in str(embedded_packet):
                # å˜—è©¦å¾Scapyå°åŒ…ä¸­æå–IPè³‡è¨Š
                if embedded_packet.haslayer('IP'):
                    source_ip = str(embedded_packet['IP'].src)
                    destination_ip = str(embedded_packet['IP'].dst)

            if hasattr(embedded_packet, 'dport'):
                destination_port = str(embedded_packet.dport)
            elif hasattr(embedded_packet, '__getitem__') and 'TCP' in str(embedded_packet):
                if embedded_packet.haslayer('TCP'):
                    source_port = str(embedded_packet['TCP'].sport)
                    destination_port = str(embedded_packet['TCP'].dport)

        except Exception as e:
            print(f"âš ï¸  æå–å°åŒ…è³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        # ç¢ºå®šServiceIDï¼ˆUUIDï¼‰
        service_id = str(self.record_uuid)

        # å¦‚æœæœ‰metadataï¼Œä½¿ç”¨å…¶ä¸­çš„UUID
        if metadata and 'embed_uuid' in metadata:
            service_id = str(metadata['embed_uuid'])

        # å¦‚æœæ˜¯åˆ†ç‰‡å°åŒ…ï¼Œä½¿ç”¨åŸå§‹UUID
        if fragment_info and 'fragment_uuid' in fragment_info:
            # åˆ†ç‰‡å°åŒ…ä½¿ç”¨åŸå§‹æœå‹™çš„UUID
            service_id = str(self.record_uuid)

        # å¾åŸå§‹å°åŒ…è³‡è¨Šæå–ä¾†æºè³‡è¨Š
        if original_packet_info:
            if 'original_src' in original_packet_info:
                source_ip = str(original_packet_info['original_src'])
            if 'original_dst' in original_packet_info:
                # æ³¨æ„ï¼šé€™è£¡è¨˜éŒ„çš„æ˜¯åŸå§‹å°åŒ…çš„ç›®æ¨™ï¼Œç¾åœ¨è®Šæˆäº†åµŒå…¥å°åŒ…çš„ä¾†æºåƒè€ƒ
                pass
            if 'tcp_sport' in original_packet_info:
                source_port = str(original_packet_info['tcp_sport'])

        # å»ºç«‹è¨˜éŒ„é …ç›®
        record_entry = {
            "ServiceID": service_id,
            "Serial_Number": self.serial_counter,
            "SourceIP": source_ip,
            "SourcePort": source_port,
            "DestinationIP": destination_ip,
            "DestinationPort": destination_port,
            "å°åŒ…æ””æˆªæ™‚é–“": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3],

            # é¡å¤–çš„è©³ç´°è³‡è¨Š
            "metadata": {
                "original_packet_info": original_packet_info,
                "embed_metadata": metadata,
                "fragment_info": fragment_info,
                "packet_size": len(bytes(embedded_packet)) if hasattr(embedded_packet, '__len__') else 0,
                "is_fragment": fragment_info is not None,
                "record_timestamp": time.time()
            }
        }

        return record_entry

    def _save_to_json(self):
        """å„²å­˜è¨˜éŒ„åˆ°JSONæª”æ¡ˆ"""
        try:
            # å»ºç«‹è¼¸å‡ºè³‡æ–™çµæ§‹
            output_data = {
                "recorder_info": {
                    "service_uuid": str(self.record_uuid),
                    "total_records": len(self.records),
                    "created_time": datetime.now().isoformat(),
                    "json_filename": self.json_filename
                },
                "packet_records": self.records
            }

            # å¯«å…¥JSONæª”æ¡ˆ
            with open(self.json_filepath, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2, default=str)

        except Exception as e:
            print(f"âŒ å„²å­˜JSONæª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def record_from_embedding_result(self, embedding_result, embedded_packets):
        """
        å¾Embeddingæ¨¡çµ„çš„çµæœè¨˜éŒ„å°åŒ…

        Args:
            embedding_result (dict): å¾PacketEmbedder.processed_packetsç²å¾—çš„çµæœ
            embedded_packets (list): åµŒå…¥å¼å°åŒ…åˆ—è¡¨
        """
        try:
            if not embedded_packets:
                print("âš ï¸  æ²’æœ‰åµŒå…¥å¼å°åŒ…å¯è¨˜éŒ„")
                return False

            # è¨˜éŒ„æ¯å€‹åµŒå…¥å¼å°åŒ…
            for i, packet in enumerate(embedded_packets):
                # å»ºç«‹åˆ†ç‰‡è³‡è¨Šï¼ˆå¦‚æœé©ç”¨ï¼‰
                fragment_info = None
                if len(embedded_packets) > 1:
                    fragment_info = {
                        "fragment_uuid": embedding_result.get('fragment_uuid'),
                        "fragment_index": i,
                        "total_fragments": len(embedded_packets),
                        "is_last_fragment": (i == len(embedded_packets) - 1)
                    }

                # å»ºç«‹metadata
                metadata = {
                    "embed_uuid": embedding_result.get('original_packet_id'),
                    "embed_timestamp": embedding_result.get('timestamp'),
                    "destination": embedding_result.get('destination'),
                    "original_hash": embedding_result.get('original_hash'),
                    "original_size": embedding_result.get('original_size')
                }

                # è¨˜éŒ„å°åŒ…
                self.record_embedded_packet(
                    packet,
                    original_packet_info=None,  # å¯ä»¥å¾embedding_resultä¸­æå–
                    metadata=metadata,
                    fragment_info=fragment_info
                )

            return True

        except Exception as e:
            print(f"âŒ å¾åµŒå…¥çµæœè¨˜éŒ„å°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

    def get_statistics(self):
        """å–å¾—è¨˜éŒ„çµ±è¨ˆè³‡è¨Š"""
        with self.lock:
            fragment_count = sum(1 for record in self.records
                                 if record['metadata']['is_fragment'])

            return {
                "total_records": len(self.records),
                "fragment_records": fragment_count,
                "non_fragment_records": len(self.records) - fragment_count,
                "service_uuid": str(self.record_uuid),
                "json_filepath": str(self.json_filepath),
                "current_serial": self.serial_counter
            }

    def export_csv(self, csv_filename=None):
        """åŒ¯å‡ºè¨˜éŒ„åˆ°CSVæª”æ¡ˆ"""
        try:
            import csv

            if not csv_filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                csv_filename = f"embedded_packets_record_{timestamp}.csv"

            csv_filepath = self.save_path / csv_filename

            with open(csv_filepath, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = [
                    'ServiceID', 'Serial_Number', 'SourceIP', 'SourcePort',
                    'DestinationIP', 'DestinationPort', 'å°åŒ…æ””æˆªæ™‚é–“'
                ]
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

                writer.writeheader()
                for record in self.records:
                    # åªå¯«å…¥ä¸»è¦æ¬„ä½åˆ°CSV
                    csv_record = {field: record.get(field, '') for field in fieldnames}
                    writer.writerow(csv_record)

            print(f"âœ… CSVæª”æ¡ˆå·²åŒ¯å‡º: {csv_filepath}")
            return str(csv_filepath)

        except ImportError:
            print("âŒ ç„¡æ³•åŒ¯å…¥csvæ¨¡çµ„")
            return None
        except Exception as e:
            print(f"âŒ åŒ¯å‡ºCSVæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None


def main():
    """æ¸¬è©¦ç”¨ä¸»ç¨‹å¼"""
    print("ğŸ§ª æ¸¬è©¦Recorderæ¨¡çµ„...")

    # å»ºç«‹æ¸¬è©¦è¨˜éŒ„å™¨
    test_uuid = uuid.uuid4()
    recorder = Recorder(save_path="./test_records", current_uuid=test_uuid)

    # æ¨¡æ“¬æ¸¬è©¦è³‡æ–™
    test_metadata = {
        "embed_uuid": test_uuid,
        "embed_timestamp": datetime.now().isoformat(),
        "process_time": time.time()
    }

    # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨æ¨¡æ“¬å°åŒ…è³‡æ–™ï¼Œå¯¦éš›ä½¿ç”¨æ™‚æœƒæ˜¯Scapyå°åŒ…å°è±¡
    class MockPacket:
        def __init__(self):
            self.src = "192.168.1.100"
            self.dst = "10.0.0.1"
            self.sport = 12345
            self.dport = 8080

        def __len__(self):
            return 1024

    mock_packet = MockPacket()

    # è¨˜éŒ„æ¸¬è©¦å°åŒ…
    success = recorder.record_embedded_packet(
        mock_packet,
        original_packet_info={
            "original_src": "192.168.1.100",
            "original_dst": "8.8.8.8",
            "tcp_sport": 12345,
            "tcp_dport": 80
        },
        metadata=test_metadata
    )

    if success:
        print("âœ… æ¸¬è©¦è¨˜éŒ„æˆåŠŸ")

        # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        stats = recorder.get_statistics()
        print(f"ğŸ“Š çµ±è¨ˆè³‡è¨Š: {stats}")

        # å˜—è©¦åŒ¯å‡ºCSV
        csv_path = recorder.export_csv()
        if csv_path:
            print(f"ğŸ“„ CSVåŒ¯å‡ºæˆåŠŸ: {csv_path}")
    else:
        print("âŒ æ¸¬è©¦è¨˜éŒ„å¤±æ•—")


if __name__ == "__main__":
    main()