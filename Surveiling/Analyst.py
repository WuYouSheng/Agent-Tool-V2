#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import json
import time
import signal
import socket
import threading
import base64
import hashlib
import os
from collections import defaultdict
from datetime import datetime
from scapy.all import *

class SurveilingProcessor:
    def __init__(self, config_path="../config.json"):
        self.config_path = config_path
        self.config = {}
        self.is_running = False
        self.received_signals = []
        self.received_fragments = defaultdict(dict)
        self.processed_count = 0
        self.signal_count = 0
        self.restored_packets = []
        
        # PCAPå®šæ™‚åŒ¯å‡ºç›¸é—œ
        self.time_gen_gap = 5  # é è¨­5ç§’
        self.pcap_output_dir = "PCAP"
        self.pcap_export_enabled = False
        self.last_export_time = 0
        self.export_counter = 0
        
        # è‡¨æ™‚å°åŒ…ç·©å­˜ (ç”¨æ–¼å®šæ™‚åŒ¯å‡º)
        self.temp_restored_packets = []
        self.temp_received_packets = []  # åŸå§‹æ¥æ”¶åˆ°çš„åµŒå…¥å°åŒ…
        
        # è¨­å®šä¿¡è™Ÿè™•ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

    def load_config(self):
        """è¼‰å…¥å®Œæ•´é…ç½®"""
        try:
            with open(self.config_path,encoding='utf-8') as f:
                self.config = json.load(f)

            # é©—è­‰ service_type
            service_type = self.config.get("service_type", "").lower()
            if service_type != "surveiling":
                raise ValueError(f"æ­¤æ¨¡çµ„åƒ…æ”¯æ´ Surveiling æ¨¡å¼ï¼Œç•¶å‰é…ç½®: {service_type}")

            # é©—è­‰å¿…è¦çš„é…ç½®é …ç›®
            required_keys = [
                "service_type", "signal_listen_port", "embed_listen_port"
            ]

            missing_keys = [key for key in required_keys if key not in self.config]
            if missing_keys:
                raise ValueError(f"é…ç½®æª”æ¡ˆç¼ºå°‘å¿…è¦é …ç›®: {missing_keys}")

            # è¼‰å…¥PCAPåŒ¯å‡ºè¨­å®š
            self.time_gen_gap = self.config.get("time_gen_gap", 5)
            self.pcap_export_enabled = self.time_gen_gap > 0  # å¦‚æœè¨­å®šäº†time_gen_gapå°±å•Ÿç”¨

            print("=== ç›£æ§ç«¯é…ç½®è¼‰å…¥æˆåŠŸ ===")
            print(f"æœå‹™æ¨¡å¼: Surveilingï¼ˆç›£æ§ç«¯ï¼‰")
            print(f"ä¿¡è™Ÿç›£è½ç«¯å£: {self.config['signal_listen_port']}")
            print(f"åµŒå…¥å°åŒ…ç›£è½ç«¯å£: {self.config['embed_listen_port']}")
            
            if self.pcap_export_enabled:
                print(f"ğŸ”„ PCAPå®šæ™‚åŒ¯å‡º: å•Ÿç”¨ (æ¯ {self.time_gen_gap} ç§’)")
                print(f"ğŸ“ PCAPè¼¸å‡ºç›®éŒ„: {self.pcap_output_dir}")
                self._ensure_pcap_directory()
            else:
                print("ğŸ”„ PCAPå®šæ™‚åŒ¯å‡º: åœç”¨")
            
            print("=" * 30)

            return True

        except FileNotFoundError:
            print(f"âŒ é…ç½®æª”æ¡ˆæœªæ‰¾åˆ°: {self.config_path}")
            return False
        except json.JSONDecodeError as e:
            print(f"âŒ é…ç½®æª”æ¡ˆJSONæ ¼å¼éŒ¯èª¤: {e}")
            return False
        except Exception as e:
            print(f"âŒ è¼‰å…¥é…ç½®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

    def _ensure_pcap_directory(self):
        """ç¢ºä¿PCAPè¼¸å‡ºç›®éŒ„å­˜åœ¨"""
        try:
            if not os.path.exists(self.pcap_output_dir):
                os.makedirs(self.pcap_output_dir)
                print(f"âœ… å‰µå»ºPCAPç›®éŒ„: {self.pcap_output_dir}")
            else:
                print(f"âœ… PCAPç›®éŒ„å·²å­˜åœ¨: {self.pcap_output_dir}")
        except Exception as e:
            print(f"âŒ å‰µå»ºPCAPç›®éŒ„å¤±æ•—: {e}")
            self.pcap_export_enabled = False

    def _signal_handler(self, signum, frame):
        """è™•ç†ç³»çµ±ä¿¡è™Ÿï¼ˆCtrl+Cç­‰ï¼‰"""
        print(f"\næ”¶åˆ°çµ‚æ­¢ä¿¡è™Ÿ {signum}ï¼Œæ­£åœ¨å®‰å…¨é—œé–‰...")
        self.shutdown()

    def start_processing(self):
        """å•Ÿå‹•ç›£æ§ç«¯è™•ç†"""
        try:
            print("ğŸš€ å•Ÿå‹•ç›£æ§ç«¯ç³»çµ±...")

            # è¼‰å…¥é…ç½®
            if not self.load_config():
                return False

            self.is_running = True
            self.last_export_time = time.time()

            print("âœ… ç›£æ§ç«¯åˆå§‹åŒ–å®Œæˆ")
            print("ğŸ” é–‹å§‹ç›£è½Signalå’ŒåµŒå…¥å°åŒ…...")
            print("   ç­‰å¾…è¢«ç›£æ§ç«¯ç™¼é€è³‡æ–™")
            
            if self.pcap_export_enabled:
                print(f"   ğŸ”„ PCAPå®šæ™‚åŒ¯å‡ºå·²å•Ÿç”¨ï¼Œæ¯ {self.time_gen_gap} ç§’ç”Ÿæˆä¸€æ¬¡")
            
            print("   æŒ‰ Ctrl+C åœæ­¢ç³»çµ±\n")

            # å•Ÿå‹•å¤šå€‹ç›£è½åŸ·è¡Œç·’
            signal_thread = threading.Thread(target=self._listen_for_signals, daemon=True)
            embed_thread = threading.Thread(target=self._listen_for_embedded_packets, daemon=True)
            
            # å•Ÿå‹•PCAPå®šæ™‚åŒ¯å‡ºåŸ·è¡Œç·’
            if self.pcap_export_enabled:
                pcap_export_thread = threading.Thread(target=self._pcap_export_worker, daemon=True)
                pcap_export_thread.start()

            signal_thread.start()
            embed_thread.start()

            # ä¸»åŸ·è¡Œç·’ç­‰å¾…
            try:
                while self.is_running:
                    time.sleep(1)
            except KeyboardInterrupt:
                pass

            return True

        except Exception as e:
            print(f"âŒ å•Ÿå‹•è™•ç†ç³»çµ±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

    def _pcap_export_worker(self):
        """PCAPå®šæ™‚åŒ¯å‡ºå·¥ä½œåŸ·è¡Œç·’"""
        print(f"ğŸ”„ PCAPå®šæ™‚åŒ¯å‡ºåŸ·è¡Œç·’å•Ÿå‹• (é–“éš”: {self.time_gen_gap}ç§’)")
        
        while self.is_running:
            try:
                current_time = time.time()
                
                # æª¢æŸ¥æ˜¯å¦åˆ°äº†åŒ¯å‡ºæ™‚é–“
                if current_time - self.last_export_time >= self.time_gen_gap:
                    self._export_current_packets()
                    self.last_export_time = current_time
                
                # æ¯ç§’æª¢æŸ¥ä¸€æ¬¡
                time.sleep(1)
                
            except Exception as e:
                print(f"âŒ PCAPåŒ¯å‡ºåŸ·è¡Œç·’éŒ¯èª¤: {e}")
                time.sleep(5)  # éŒ¯èª¤æ™‚ç­‰å¾…5ç§’å†ç¹¼çºŒ

    def _export_current_packets(self):
        """åŒ¯å‡ºç•¶å‰æ™‚é–“æ®µçš„å°åŒ…"""
        try:
            # æª¢æŸ¥æ˜¯å¦æœ‰å°åŒ…éœ€è¦åŒ¯å‡º
            restored_count = len(self.temp_restored_packets)
            received_count = len(self.temp_received_packets)
            
            if restored_count == 0 and received_count == 0:
                return  # æ²’æœ‰å°åŒ…ï¼Œè·³éé€™æ¬¡åŒ¯å‡º
            
            self.export_counter += 1
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            print(f"\nğŸ’¾ å®šæ™‚PCAPåŒ¯å‡º #{self.export_counter} ({timestamp})")
            
            files_created = []
            
            # åŒ¯å‡ºé‚„åŸå°åŒ…
            if restored_count > 0:
                restored_filename = os.path.join(
                    self.pcap_output_dir, 
                    f"restored_{timestamp}_{self.export_counter:03d}.pcap"
                )
                
                try:
                    packets_to_export = [info['packet'] for info in self.temp_restored_packets]
                    wrpcap(restored_filename, packets_to_export)
                    files_created.append(restored_filename)
                    print(f"   âœ… é‚„åŸå°åŒ…: {restored_filename} ({restored_count} å€‹å°åŒ…)")
                except Exception as e:
                    print(f"   âŒ é‚„åŸå°åŒ…åŒ¯å‡ºå¤±æ•—: {e}")
            
            # åŒ¯å‡ºåŸå§‹æ¥æ”¶å°åŒ…
            if received_count > 0:
                received_filename = os.path.join(
                    self.pcap_output_dir, 
                    f"received_{timestamp}_{self.export_counter:03d}.pcap"
                )
                
                try:
                    packets_to_export = [info['packet'] for info in self.temp_received_packets]
                    wrpcap(received_filename, packets_to_export)
                    files_created.append(received_filename)
                    print(f"   âœ… æ¥æ”¶å°åŒ…: {received_filename} ({received_count} å€‹å°åŒ…)")
                except Exception as e:
                    print(f"   âŒ æ¥æ”¶å°åŒ…åŒ¯å‡ºå¤±æ•—: {e}")
            
            # é¡¯ç¤ºåŒ¯å‡ºçµ±è¨ˆ
            if files_created:
                total_size = sum(os.path.getsize(f) for f in files_created)
                print(f"   ğŸ“Š åŒ¯å‡ºçµ±è¨ˆ: {len(files_created)} å€‹æª”æ¡ˆ, ç¸½å¤§å°: {total_size/1024:.1f} KB")
            
            # æ¸…ç©ºæš«å­˜
            self.temp_restored_packets.clear()
            self.temp_received_packets.clear()
            
        except Exception as e:
            print(f"âŒ åŒ¯å‡ºå°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def _listen_for_signals(self):
        """ç›£è½ä¿¡è™Ÿå°åŒ…"""
        try:
            port = self.config["signal_listen_port"]
            server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            server_socket.bind(('0.0.0.0', port))
            server_socket.listen(5)
            server_socket.settimeout(1)

            print(f"ğŸ” é–‹å§‹ç›£è½ä¿¡è™Ÿå°åŒ…ï¼Œç«¯å£: {port}")

            while self.is_running:
                try:
                    client_socket, address = server_socket.accept()

                    data = client_socket.recv(1024)
                    if data:
                        signal_info = json.loads(data.decode('utf-8'))
                        self._handle_received_signal(signal_info, address)

                    client_socket.close()

                except socket.timeout:
                    continue
                except Exception as e:
                    if self.is_running:
                        print(f"âš ï¸  æ¥æ”¶ä¿¡è™Ÿå°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

            server_socket.close()

        except Exception as e:
            print(f"âŒ ç›£è½ä¿¡è™Ÿå°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def _handle_received_signal(self, signal_info, sender_address):
        """è™•ç†æ¥æ”¶åˆ°çš„ä¿¡è™Ÿå°åŒ…"""
        try:
            self.signal_count += 1

            print(f"\nğŸš¨ æ”¶åˆ°ä¿¡è™Ÿå°åŒ… #{self.signal_count}!")
            print(f"   ä¾†æº: {sender_address[0]}:{sender_address[1]}")
            print(f"   æ™‚é–“æˆ³: {signal_info.get('timestamp', 'unknown')}")
            print(f"   UUID: {signal_info.get('uuid', 'unknown')}")
            print(f"   ä¿¡è™Ÿé¡å‹: {signal_info.get('signal_type', 'unknown')}")

            # è¨˜éŒ„ä¿¡è™Ÿ
            self.received_signals.append({
                "signal_info": signal_info,
                "sender": sender_address,
                "received_time": time.time()
            })

            print(f"   âœ… ä¿¡è™Ÿå·²è¨˜éŒ„ï¼Œä¾†æºä¸»æ©Ÿ {sender_address[0]} å·²è­˜åˆ¥")
            print(f"   ğŸ“Š å·²æ¥æ”¶ä¿¡è™Ÿç¸½æ•¸: {self.signal_count}\n")

        except Exception as e:
            print(f"âŒ è™•ç†ä¿¡è™Ÿå°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def _listen_for_embedded_packets(self):
        """ç›£è½åµŒå…¥å°åŒ…"""
        try:
            port = self.config["embed_listen_port"]

            print(f"ğŸ” é–‹å§‹ç›£è½åµŒå…¥å°åŒ…ï¼Œç«¯å£: {port}")

            def packet_handler(packet):
                if TCP in packet and packet[TCP].dport == port:
                    self._handle_received_embedded_packet(packet)

            # è¨­å®šéæ¿¾å™¨
            filter_str = f"tcp dst port {port}"

            # é€™æœƒåœ¨èƒŒæ™¯åŸ·è¡Œç›´åˆ°ç¨‹å¼çµæŸ
            sniff(filter=filter_str, prn=packet_handler, store=0, stop_filter=lambda x: not self.is_running)

        except Exception as e:
            print(f"âŒ ç›£è½åµŒå…¥å°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def _handle_received_embedded_packet(self, packet):
        """è™•ç†æ¥æ”¶åˆ°çš„åµŒå…¥å°åŒ…"""
        try:
            if Raw not in packet:
                return

            payload = packet[Raw].load.decode('utf-8')

            print(f"\nğŸ“¥ æ”¶åˆ°åµŒå…¥å°åŒ…")
            print(f"   ä¾†æº: {packet[IP].src}:{packet[TCP].sport}")
            print(f"   å¤§å°: {len(payload)} bytes")

            # å¦‚æœå•Ÿç”¨PCAPåŒ¯å‡ºï¼Œå°‡åŸå§‹å°åŒ…åŠ å…¥æš«å­˜
            if self.pcap_export_enabled:
                received_packet_info = {
                    'packet': packet,
                    'timestamp': time.time(),
                    'size': len(bytes(packet))
                }
                self.temp_received_packets.append(received_packet_info)

            # è§£æå°åŒ…å…§å®¹
            try:
                data = json.loads(payload)
                
                # å…ˆæª¢æŸ¥æ•¸æ“šçµæ§‹
                print(f"   ğŸ“‹ å°åŒ…çµæ§‹: {list(data.keys())}")

                if "fragment_info" in data:
                    # é€™æ˜¯åˆ†ç‰‡å°åŒ…
                    print("   ğŸ“¦ è­˜åˆ¥ç‚ºåˆ†ç‰‡å°åŒ…")
                    self._handle_embedded_fragment(data, packet)
                elif "metadata" in data and "original_packet" in data:
                    # é€™æ˜¯å®Œæ•´å°åŒ…
                    print("   ğŸ“‹ è­˜åˆ¥ç‚ºå®Œæ•´å°åŒ…")
                    self._handle_complete_embedded_packet(data, packet)
                else:
                    # æª¢æŸ¥æ˜¯å¦æ˜¯ç°¡åŒ–ç‰ˆæœ¬çš„å°åŒ…
                    print("   âš ï¸  æœªçŸ¥çš„å°åŒ…æ ¼å¼ï¼Œå˜—è©¦ç°¡åŒ–è™•ç†")
                    print(f"   æ•¸æ“šéµå€¼: {list(data.keys())}")
                    
                    # å˜—è©¦è™•ç†ç°¡åŒ–ç‰ˆæœ¬
                    if any(key in data for key in ['embed_uuid', 'original_packet', 'data']):
                        print("   ğŸ”„ å˜—è©¦ç°¡åŒ–æ ¼å¼è™•ç†")
                        self._handle_simplified_embedded_packet(data, packet)
                    else:
                        print("   âŒ ç„¡æ³•è­˜åˆ¥çš„å°åŒ…æ ¼å¼")

            except json.JSONDecodeError as e:
                print(f"   âŒ JSONè§£æå¤±æ•—: {e}")
                print(f"   å‰100å­—å…ƒ: {payload[:100]}")

        except UnicodeDecodeError as e:
            print(f"   âŒ UTF-8è§£ç¢¼å¤±æ•—: {e}")
        except Exception as e:
            print(f"âŒ è™•ç†åµŒå…¥å°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

    def _handle_simplified_embedded_packet(self, data, source_packet):
        """è™•ç†ç°¡åŒ–æ ¼å¼çš„åµŒå…¥å°åŒ…"""
        try:
            print("   ğŸ”§ è™•ç†ç°¡åŒ–æ ¼å¼å°åŒ…")
            
            # å°‹æ‰¾metadataå’Œoriginal_packet
            metadata = None
            original_packet_data = None
            
            # æª¢æŸ¥ä¸åŒçš„å¯èƒ½çµæ§‹
            if "metadata" in data:
                metadata = data["metadata"]
            elif "embed_uuid" in data:
                # æ§‹å»ºç°¡åŒ–çš„metadata
                metadata = {
                    "embed_uuid": data.get("embed_uuid", "unknown"),
                    "embed_timestamp": data.get("embed_timestamp", "unknown")
                }
            
            if "original_packet" in data:
                original_packet_data = data["original_packet"]
            elif "data" in data:
                # å¯èƒ½æ˜¯ç›´æ¥çš„æ•¸æ“šæ ¼å¼
                original_packet_data = {
                    "data": data["data"],
                    "length": data.get("length", 0),
                    "original_hash": data.get("original_hash", "")
                }
            
            if metadata and original_packet_data:
                print("   âœ… æˆåŠŸè§£æç°¡åŒ–æ ¼å¼")
                self._process_extracted_packet(metadata, original_packet_data)
            else:
                print("   âŒ ç°¡åŒ–æ ¼å¼è§£æå¤±æ•—")
                print(f"   metadata: {'âœ…' if metadata else 'âŒ'}")
                print(f"   original_packet_data: {'âœ…' if original_packet_data else 'âŒ'}")
                
        except Exception as e:
            print(f"   âŒ ç°¡åŒ–æ ¼å¼è™•ç†éŒ¯èª¤: {e}")

    def _handle_embedded_fragment(self, fragment_data, source_packet):
        """è™•ç†åµŒå…¥å°åŒ…åˆ†ç‰‡"""
        try:
            fragment_info = fragment_data["fragment_info"]
            fragment_uuid = fragment_info["fragment_uuid"]
            fragment_index = fragment_info["fragment_index"]
            total_fragments = fragment_info["total_fragments"]

            print(f"   ğŸ“¦ åˆ†ç‰‡å°åŒ…: {fragment_uuid[:8]}... [{fragment_index + 1}/{total_fragments}]")

            # å„²å­˜åˆ†ç‰‡
            self.received_fragments[fragment_uuid][fragment_index] = fragment_data

            # æª¢æŸ¥æ˜¯å¦æ”¶é›†å®Œæ‰€æœ‰åˆ†ç‰‡
            if len(self.received_fragments[fragment_uuid]) == total_fragments:
                print(f"   âœ… æ‰€æœ‰åˆ†ç‰‡å·²æ”¶åˆ°ï¼Œé–‹å§‹é‡çµ„")
                self._reassemble_and_process(fragment_uuid)

        except Exception as e:
            print(f"âŒ è™•ç†åˆ†ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def _reassemble_and_process(self, fragment_uuid):
        """é‡çµ„åˆ†ç‰‡ä¸¦è™•ç†åŸå§‹å°åŒ…"""
        try:
            fragments = self.received_fragments[fragment_uuid]

            # æŒ‰ç´¢å¼•æ’åº
            sorted_fragments = sorted(fragments.items())

            # é‡çµ„æ•¸æ“š
            reassembled_data = b""
            for _, fragment_data in sorted_fragments:
                fragment_bytes = base64.b64decode(fragment_data["data"])
                reassembled_data += fragment_bytes

            # è§£æå®Œæ•´æ•¸æ“š
            complete_data = json.loads(reassembled_data.decode('utf-8'))

            # è™•ç†å®Œæ•´å°åŒ…
            self._handle_complete_embedded_packet(complete_data, None)

            # æ¸…ç†åˆ†ç‰‡ç·©å­˜
            del self.received_fragments[fragment_uuid]

        except Exception as e:
            print(f"âŒ é‡çµ„åˆ†ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def _handle_complete_embedded_packet(self, embedded_data, source_packet):
        """è™•ç†å®Œæ•´çš„åµŒå…¥å°åŒ…ä¸¦é‚„åŸåŸå§‹å°åŒ… - ä¿®å¾©ç‰ˆæœ¬"""
        try:
            # å®‰å…¨åœ°ç²å–metadataå’Œoriginal_packet
            metadata = embedded_data.get("metadata")
            original_packet_data = embedded_data.get("original_packet")
            
            if not metadata:
                print("   âŒ ç¼ºå°‘metadata")
                return
                
            if not original_packet_data:
                print("   âŒ ç¼ºå°‘original_packet")
                return
            
            self._process_extracted_packet(metadata, original_packet_data)

        except Exception as e:
            print(f"âŒ è™•ç†å®Œæ•´åµŒå…¥å°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

    def _process_extracted_packet(self, metadata, original_packet_data):
        """è™•ç†æå–çš„å°åŒ…æ•¸æ“š"""
        try:
            print(f"\nğŸ¯ é‚„åŸåŸå§‹å°åŒ…:")
            print(f"   åµŒå…¥UUID: {metadata.get('embed_uuid', 'unknown')}")
            print(f"   åµŒå…¥æ™‚é–“: {metadata.get('embed_timestamp', 'unknown')}")
            print(f"   åŸå§‹ä¾†æº: {original_packet_data.get('original_src', 'unknown')}")
            print(f"   åŸå§‹ç›®æ¨™: {original_packet_data.get('original_dst', 'unknown')}")
            print(f"   åŸå§‹å”è­°: {original_packet_data.get('original_protocol', 'unknown')}")
            print(f"   åŸå§‹å¤§å°: {original_packet_data.get('length', 'unknown')} bytes")

            # ç²å–åŸå§‹é›œæ¹Šå€¼ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            expected_hash = original_packet_data.get('original_hash', '')
            if expected_hash:
                print(f"   æœŸæœ›é›œæ¹Š: {expected_hash[:16]}...")

            # é‡å»ºåŸå§‹å°åŒ…
            original_data_b64 = original_packet_data.get("data")
            if not original_data_b64:
                print("   âŒ ç¼ºå°‘å°åŒ…æ•¸æ“š")
                return
                
            original_bytes = base64.b64decode(original_data_b64)

            # é©—è­‰æ•¸æ“šå®Œæ•´æ€§
            actual_hash = hashlib.sha256(original_bytes).hexdigest()
            print(f"   å¯¦éš›é›œæ¹Š: {actual_hash[:16]}...")

            if expected_hash and actual_hash != expected_hash:
                print(f"   âš ï¸  è³‡æ–™å®Œæ•´æ€§é©—è­‰å¤±æ•—!")
                print(f"      æœŸæœ›: {expected_hash}")
                print(f"      å¯¦éš›: {actual_hash}")

            try:
                # æ™ºèƒ½é‚„åŸ - æ ¹æ“šå±¤ç´šè³‡è¨Šæ±ºå®šé‚„åŸæ–¹å¼
                layers = original_packet_data.get('layers', [])
                print(f"   å°åŒ…å±¤ç´š: {' / '.join(layers) if layers else 'æœªçŸ¥'}")

                # æ ¹æ“šåŸå§‹å°åŒ…çš„å±¤ç´šçµæ§‹é¸æ“‡é‚„åŸæ–¹å¼
                if layers:
                    if "Ether" in layers:
                        # åŸå§‹å°åŒ…æœ‰Etherå±¤
                        original_packet = Ether(original_bytes)
                        print(f"   ğŸ“‹ å¾Etherå±¤é‚„åŸ")
                    elif "IP" in layers:
                        # åŸå§‹å°åŒ…å¾IPå±¤é–‹å§‹
                        original_packet = IP(original_bytes)
                        print(f"   ğŸ“‹ å¾IPå±¤é‚„åŸ")
                    else:
                        # æœªçŸ¥çµæ§‹ï¼Œå˜—è©¦Ether
                        original_packet = Ether(original_bytes)
                        print(f"   ğŸ“‹ é è¨­å¾Etherå±¤é‚„åŸ")
                else:
                    # æ²’æœ‰å±¤ç´šè³‡è¨Šï¼Œå˜—è©¦æ™ºèƒ½åˆ¤æ–·
                    if len(original_bytes) > 14 and original_bytes[12:14] == b'\x08\x00':
                        # çœ‹èµ·ä¾†åƒEthernet + IPv4
                        original_packet = Ether(original_bytes)
                        print(f"   ğŸ“‹ æª¢æ¸¬åˆ°Ethernet headerï¼Œå¾Etherå±¤é‚„åŸ")
                    elif len(original_bytes) > 0 and (original_bytes[0] >> 4) == 4:
                        # çœ‹èµ·ä¾†åƒIPv4
                        original_packet = IP(original_bytes)
                        print(f"   ğŸ“‹ æª¢æ¸¬åˆ°IPv4ï¼Œå¾IPå±¤é‚„åŸ")
                    else:
                        # é è¨­ä½¿ç”¨Ether
                        original_packet = Ether(original_bytes)
                        print(f"   ğŸ“‹ ç„¡æ³•åˆ¤æ–·ï¼Œé è¨­å¾Etherå±¤é‚„åŸ")

                print(f"   âœ… åŸå§‹å°åŒ…é‡å»ºæˆåŠŸ")

                # è¨ˆç®—é‚„åŸå¾Œçš„é›œæ¹Šå€¼
                restored_hash = hashlib.sha256(bytes(original_packet)).hexdigest()
                print(f"   é‚„åŸé›œæ¹Š: {restored_hash[:16]}...")

                # å„²å­˜é‚„åŸçš„å°åŒ…ç”¨æ–¼æ¯”è¼ƒ
                restored_info = {
                    'timestamp': time.time(),
                    'packet': original_packet,
                    'size': len(bytes(original_packet)),
                    'hash': restored_hash,
                    'metadata': metadata,
                    'original_hash': expected_hash,
                    'data_integrity_ok': (actual_hash == expected_hash) if expected_hash else True,
                    'restoration_method': 'smart_detection'
                }
                
                self.restored_packets.append(restored_info)
                
                # å¦‚æœå•Ÿç”¨PCAPåŒ¯å‡ºï¼Œä¹ŸåŠ å…¥æš«å­˜
                if self.pcap_export_enabled:
                    self.temp_restored_packets.append(restored_info)

                # æ›´æ–°çµ±è¨ˆ
                self.processed_count += 1

                # é€²è¡Œé€²ä¸€æ­¥è™•ç†
                self._analyze_original_packet(original_packet, metadata)

                print(f"   ğŸ“Š å·²è™•ç†åµŒå…¥å°åŒ…ç¸½æ•¸: {self.processed_count}")
                
                # é›œæ¹Šæ¯”è¼ƒçµæœ
                if expected_hash:
                    if actual_hash == expected_hash:
                        print(f"   âœ… è³‡æ–™å®Œæ•´æ€§é©—è­‰é€šé")
                    else:
                        print(f"   âŒ è³‡æ–™å®Œæ•´æ€§é©—è­‰å¤±æ•—")
                
                print(f"{'=' * 60}\n")

            except Exception as e:
                print(f"   âŒ é‡å»ºåŸå§‹å°åŒ…å¤±æ•—: {e}")
                print(f"   åŸå§‹æ•¸æ“šå‰32ä½å…ƒçµ„: {original_bytes[:32].hex()}")

        except Exception as e:
            print(f"âŒ è™•ç†æå–å°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

    def _analyze_original_packet(self, original_packet, metadata):
        """åˆ†æé‚„åŸçš„åŸå§‹å°åŒ…"""
        try:
            print(f"   ğŸ” å°åŒ…åˆ†æ:")

            # åˆ†æIPå±¤
            if IP in original_packet:
                ip_layer = original_packet[IP]
                print(f"      IP: {ip_layer.src} -> {ip_layer.dst}")
                print(f"      TTL: {ip_layer.ttl}, å”è­°: {ip_layer.proto}")

                # åˆ†æTCPå±¤
                if TCP in original_packet:
                    tcp_layer = original_packet[TCP]
                    print(f"      TCP: Port {tcp_layer.sport} -> {tcp_layer.dport}")
                    print(f"      Flags: {tcp_layer.flags}")

                    # åˆ†æPayload
                    if Raw in original_packet:
                        payload = original_packet[Raw].load
                        print(f"      Payload: {len(payload)} bytes")

                        # å˜—è©¦æª¢æ¸¬HTTP
                        try:
                            payload_str = payload.decode('utf-8', errors='ignore')
                            if any(method in payload_str for method in ['GET', 'POST', 'PUT', 'DELETE']):
                                lines = payload_str.split('\n')
                                print(f"      HTTPè«‹æ±‚: {lines[0][:100]}...")
                        except:
                            pass

        except Exception as e:
            print(f"   âš ï¸  åˆ†æå°åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def export_packets_to_pcap(self, filename="captured_packets.pcap"):
        """åŒ¯å‡ºé‚„åŸçš„å°åŒ…åˆ°PCAPæª”æ¡ˆ"""
        try:
            if self.restored_packets:
                packets = [info['packet'] for info in self.restored_packets]
                wrpcap(filename, packets)
                print(f"   ğŸ’¾ å·²åŒ¯å‡º {len(packets)} å€‹é‚„åŸå°åŒ…åˆ° {filename}")
                return filename
            else:
                print(f"   âš ï¸  æ²’æœ‰é‚„åŸå°åŒ…å¯åŒ¯å‡º")
                return None
        except Exception as e:
            print(f"   âŒ åŒ¯å‡ºå°åŒ…å¤±æ•—: {e}")
            return None

    def get_statistics(self):
        """å–å¾—è©³ç´°çµ±è¨ˆè³‡è¨Š"""
        return {
            "received_signals": self.signal_count,
            "processed_packets": self.processed_count,
            "restored_packets_count": len(self.restored_packets),
            "pending_fragments": len(self.received_fragments),
            "pcap_export_enabled": self.pcap_export_enabled,
            "pcap_export_counter": self.export_counter,
            "time_gen_gap": self.time_gen_gap,
            "fragment_details": {
                uuid[:8]: len(fragments)
                for uuid, fragments in self.received_fragments.items()
            },
            "signal_sources": list(set(
                signal["sender"][0] for signal in self.received_signals
            )),
            "data_integrity_stats": {
                "total_with_hash": len([p for p in self.restored_packets if p.get('original_hash')]),
                "integrity_ok": len([p for p in self.restored_packets if p.get('data_integrity_ok', True)]),
                "integrity_failed": len([p for p in self.restored_packets if not p.get('data_integrity_ok', True)])
            }
        }

    def shutdown(self):
        """å®‰å…¨é—œé–‰ç³»çµ±"""
        print("\nğŸ›‘ æ­£åœ¨é—œé–‰ç›£æ§ç«¯ç³»çµ±...")

        self.is_running = False

        # å¦‚æœå•Ÿç”¨PCAPåŒ¯å‡ºï¼ŒåŸ·è¡Œæœ€å¾Œä¸€æ¬¡åŒ¯å‡º
        if self.pcap_export_enabled and (self.temp_restored_packets or self.temp_received_packets):
            print("ğŸ”„ åŸ·è¡Œæœ€å¾Œä¸€æ¬¡PCAPåŒ¯å‡º...")
            self._export_current_packets()

        # é¡¯ç¤ºè©³ç´°çµ±è¨ˆè³‡è¨Š
        stats = self.get_statistics()

        print(f"\nğŸ“Š ç›£æ§ç«¯çµ±è¨ˆ:")
        print(f"   å·²æ¥æ”¶ä¿¡è™Ÿæ•¸: {stats['received_signals']}")
        print(f"   å·²è™•ç†å°åŒ…æ•¸: {stats['processed_packets']}")
        print(f"   å·²é‚„åŸå°åŒ…æ•¸: {stats['restored_packets_count']}")
        print(f"   å¾…è™•ç†åˆ†ç‰‡: {stats['pending_fragments']}")

        # PCAPåŒ¯å‡ºçµ±è¨ˆ
        if stats['pcap_export_enabled']:
            print(f"   PCAPå®šæ™‚åŒ¯å‡º: âœ… å•Ÿç”¨")
            print(f"   åŒ¯å‡ºé–“éš”: {stats['time_gen_gap']} ç§’")
            print(f"   å·²åŒ¯å‡ºæ‰¹æ¬¡: {stats['pcap_export_counter']} æ¬¡")
            
            # è¨ˆç®—PCAPæª”æ¡ˆç¸½æ•¸å’Œå¤§å°
            pcap_files = []
            total_size = 0
            try:
                import glob
                pcap_pattern = os.path.join(self.pcap_output_dir, "*.pcap")
                pcap_files = glob.glob(pcap_pattern)
                total_size = sum(os.path.getsize(f) for f in pcap_files)
                print(f"   PCAPæª”æ¡ˆç¸½æ•¸: {len(pcap_files)} å€‹")
                print(f"   PCAPæª”æ¡ˆç¸½å¤§å°: {total_size/1024:.1f} KB")
            except Exception as e:
                print(f"   PCAPçµ±è¨ˆè¨ˆç®—éŒ¯èª¤: {e}")
        else:
            print(f"   PCAPå®šæ™‚åŒ¯å‡º: âŒ åœç”¨")

        # è³‡æ–™å®Œæ•´æ€§çµ±è¨ˆ
        integrity_stats = stats['data_integrity_stats']
        if integrity_stats['total_with_hash'] > 0:
            success_rate = (integrity_stats['integrity_ok'] / integrity_stats['total_with_hash']) * 100
            print(f"   è³‡æ–™å®Œæ•´æ€§: {success_rate:.1f}% ({integrity_stats['integrity_ok']}/{integrity_stats['total_with_hash']})")

        if stats['signal_sources']:
            print(f"   ä¿¡è™Ÿä¾†æº: {', '.join(stats['signal_sources'])}")

        if stats['fragment_details']:
            print(f"   æœªå®Œæˆåˆ†ç‰‡: {list(stats['fragment_details'].keys())}")

        # è‡ªå‹•åŒ¯å‡ºæœ€çµ‚çš„é‚„åŸå°åŒ…
        if self.restored_packets:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            final_pcap_file = f"final_restored_packets_{timestamp}.pcap"
            self.export_packets_to_pcap(final_pcap_file)

        print("âœ… ç›£æ§ç«¯å·²å®‰å…¨é—œé–‰")

    def get_status(self):
        """å–å¾—ç³»çµ±ç‹€æ…‹"""
        return {
            "is_running": self.is_running,
            "service_mode": "Surveiling",
            "received_signals": self.signal_count,
            "processed_packets": self.processed_count,
            "restored_packets_count": len(self.restored_packets),
            "pending_fragments": len(self.received_fragments),
            "pcap_export_enabled": self.pcap_export_enabled,
            "pcap_export_counter": self.export_counter,
            "config": self.config
        }


def main():
    """ä¸»ç¨‹å¼é€²å…¥é»"""
    print("=" * 60)
    print("ğŸ‘ï¸ ç›£æ§ç«¯ç³»çµ± (PCAPå®šæ™‚åŒ¯å‡ºç‰ˆ)")
    print("   æ¥æ”¶Signalå’ŒåµŒå…¥å°åŒ…ä¸¦é‚„åŸåˆ†æ")
    print("   æ”¯æ´æ™ºèƒ½å°åŒ…é‚„åŸå’Œå®Œæ•´æ€§é©—è­‰")
    print("   æ”¯æ´å®šæ™‚PCAPæª”æ¡ˆåŒ¯å‡ºåŠŸèƒ½")
    print("=" * 60)

    # å»ºç«‹è™•ç†å™¨å¯¦ä¾‹
    processor = SurveilingProcessor(config_path="./config_surveiling_sample.json")

    try:
        # å•Ÿå‹•è™•ç†ç³»çµ±
        success = processor.start_processing()

        if not success:
            print("âŒ ç›£æ§ç«¯ç³»çµ±å•Ÿå‹•å¤±æ•—")
            return 1

    except KeyboardInterrupt:
        print("\nâš ï¸  æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿ")
    except Exception as e:
        print(f"âŒ ç³»çµ±é‹è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 1
    finally:
        processor.shutdown()

    return 0


if __name__ == "__main__":
    sys.exit(main())